<html><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252">
<title>Cross-modal Attribute Transfer for Rescaling 3D Models</title>
<link href="./files/style.css" rel="stylesheet" type="text/css">
</head>

<body>

<div class="pageTitle">
  Cross-modal Attribute Transfer for Rescaling 3D Models<br>
  <br>
  <span class="Authors">
        <a href="https://linsats.github.io/" target="_blank">Lin Shao</a> &nbsp; &nbsp;
        <a href="https://angelxuanchang.github.io/" target="_blank">Angel X. Chang</a> &nbsp; &nbsp;
        <a href="http://ai.stanford.edu/~haosu/" target="_blank">Hao Su</a> &nbsp; &nbsp;
        <a href="http://msavva.github.io/" target="_blank">Manolis Savva</a> &nbsp; &nbsp;
        <a href="http://geometry.stanford.edu/member/guibas/" target="_blank">Leonidas J. Guibas</a> &nbsp; &nbsp;<br>
        <a href="http://www.stanford.edu/" target="_blank">Stanford University </a>
        <a href="https://www.princeton.edu/" target="_blank">  Princeton University  </a>
        <a href="https://ucsd.edu/" target="_blank">  University of California San Diego </a>
        <br><br>
	International Conference on 3D Vision (3DV) 2017
  </span>
  </div>

<br>

  <img class="bannerImage" src="./files/teaser.png" ,="" width="800"><br>
  <table width="800" align="center"><tbody><tr><td><p class="figureTitleText">Figure 1.: Left: we connect 3D models to webpages with physical attributes. Our approach transfers real-world dimensions
by cross-modal linking through text or images (purple and orange links correspondingly). Right: we transfer real-world
dimensions to a 3D model dataset and rectify physically implausible model scales <b> </p></td></tr></tbody></table>

  <div class="abstractTitle">
  Abstract
  </div>
  <p class="abstractText">
  We present an algorithm for transferring physical attributes between webpages and 3D shapes. We crawl product catalogues and other webpages with structured metadata containing physical attributes such as dimensions and weights. Then we transfer physical attributes between shapes and real-world objects using a joint embedding of images and 3D shapes and a view-based weighting and aspect ratio filtering scheme for instance-level linking of 3D models and real-world counterpart objects. We evaluate our approach on a large-scale dataset of unscaled 3D models, and show that we outperform prior work on rescaling 3D models that considers only category-level size priors.
</p>

<p><em><a href="" target="_blank">Paper</a> | <a href="" target="_blank">Data</a></p> 

  <div class="projectTitle">
  Bibtex
  </div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
@inproceedings{lin2017crossmodal, 
title={Cross-modal Attribute Transfer for Rescaling {3D} Models}, 
author={Shao, Lin and Chang, Angel X. and Su, Hao and Savva, Manolis and Guibas, Leonidas}, 
booktitle = {Proceedings of the International Conference on {3D} Vision ({3DV})}, year={2017} 
}</code></pre></div></div>



</body><div></div></html>
